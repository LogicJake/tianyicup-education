{"cells":[{"metadata":{"id":"FE4280F8AE5D42408092DC3742FBC80F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import gc\nimport os\nimport sys\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectPercentile, f_classif, chi2\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import Binarizer, LabelEncoder, scale\n\nwarnings.filterwarnings('ignore')","execution_count":2},{"metadata":{"id":"2AE13D120CA843C98258AA49B63A91A9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"data_path = '/home/kesci/input/smart_edu7557'\ncurrent_path = '/home/kesci/work'\n\ndimension = 60\nseed=7","execution_count":3},{"metadata":{"id":"D51A910ADC5D4E418B363F7E47723755","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 简单统计\ndef stat(df, df_merge, group_by, agg):\n    group = df.groupby(group_by).agg(agg)\n\n    columns = []\n    for on, methods in agg.items():\n        for method in methods:\n            columns.append('{}_{}_{}'.format('_'.join(group_by), on, method))\n    group.columns = columns\n    group.reset_index(inplace=True)\n    df_merge = df_merge.merge(group, on=group_by, how='left')\n\n    del (group)\n    gc.collect()\n    return df_merge","execution_count":4},{"metadata":{"id":"AC7CE01A1C9945D7B96AF9F5794F8FD5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# cv 统计\ndef stat_cv(df, df_merge, group_by, on):\n    group = df.groupby(group_by).agg({on: ['std', 'mean']})\n    group.columns = ['std', 'mean']\n    group.reset_index(inplace=True)\n\n    group['cv'] = group['std'] / group['mean']\n    group.drop(['std', 'mean'], axis=1, inplace=True)\n\n    group.columns = group_by + ['{}_{}_cv'.format('_'.join(group_by), on)]\n    df_merge = df_merge.merge(group, on=group_by, how='left')\n\n    del (group)\n    gc.collect()\n    return df_merge","execution_count":5},{"metadata":{"id":"4DE378087C384C6EBED6CB487750A974","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# rank 统计\ndef stat_rank(df, df_merge, group_by):\n    df_temp = df.copy(deep=True)\n    df_temp['rank'] = df.groupby(['exam_id'])['score'].rank(method='min',\n                                                            ascending=False)\n\n    df_temp = df_temp.groupby(group_by)['rank'].mean().to_frame()\n    df_temp.reset_index(inplace=True)\n    df_temp.columns = group_by + ['{}_rank_mean'.format('_'.join(group_by))]\n\n    df_merge = df_merge.merge(df_temp, how='left')\n    return df_merge","execution_count":6},{"metadata":{"id":"82B4615FAB674108B1E0183F63121271","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# student score mean / exam mean score\ndef stat_ratio_mean(df, df_merge, group_by):\n    df_temp = df.copy(deep=True)\n    df_temp['exam_mean_score'] = df.groupby(['exam_id'\n                                             ])['score'].transform('mean')\n    df_temp['student_score_ratio_exam_mean_score'] = df_temp[\n        'score'] / df_temp['exam_mean_score']\n\n    df_temp = df_temp.groupby(\n        group_by)['student_score_ratio_exam_mean_score'].mean().to_frame()\n    df_temp.reset_index(inplace=True)\n    df_temp.columns = group_by + [\n        'student_score_ratio_exam_mean_score_{}_mean'.format(\n            '_'.join(group_by))\n    ]\n\n    df_merge = df_merge.merge(df_temp, how='left')\n    return df_merge","execution_count":7},{"metadata":{"id":"8FD1F2A406D24E90A0F0DC36665F8FCA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def gen_feature(df, index, columns, values):\n    p = df.pivot_table(index=index, columns=columns,\n                       values=values).reset_index().fillna(0)\n    columns = p.columns.values.tolist()\n    columns = ['{}_{}'.format(c, values) if c != index else c for c in columns]\n    p.columns = columns\n\n    return p","execution_count":8},{"metadata":{"id":"1DC3505B913F485CA7010A44D7BB6752","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def select_feature(df):\n    p = 86\n\n    df.fillna(0, inplace=True)\n    ycol = 'score'\n    feature_names = [f for f in df.columns if f not in [ycol, 'student_id', 'course', 'exam_id']]\n\n    X = df[feature_names]\n    Y = df[ycol]\n    X_bin = Binarizer().fit_transform(scale(X))\n\n    selectChi2 = SelectPercentile(chi2, percentile=p).fit(X_bin, Y)\n    selectF_classif = SelectPercentile(f_classif, percentile=p).fit(X, Y)\n\n    chi2_selected = selectChi2.get_support()\n    print('Chi2 selected {} features.'.format(chi2_selected.sum()))\n    f_classif_selected = selectF_classif.get_support()\n    print('F_classif selected {} features.'.format(f_classif_selected.sum()))\n    selected = chi2_selected & f_classif_selected\n    print('Chi2 & F_classif selected {} features'.format(selected.sum()))\n    features = [f for f, s in zip(feature_names, selected) if s]\n\n    x = list(set(feature_names) - set(features))\n    x.sort()\n    print(x)\n    df_sel = df[features]\n    df_basic = df[[ycol, 'student_id', 'course', 'exam_id']]\n    df_sel = pd.concat([df_sel, df_basic], axis=1)\n    return df_sel","execution_count":9},{"metadata":{"id":"C0145AFFC2434835929D223F5D58F0E3","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"ids = ['t3gjIJ4S', 'XHQ4brE1', 'Dm8lzpUM', '7lQGsPpC', 'ldofMGhb', 'wUfEa8v2', 'YFZJ4rei', \n       '6gjiTmw7', '29N5PmSt', 'N43ekjOH', 'fkVo7mcd', '3TMeQo5F', 'aY0jKoh1', 'Bcn8WGsT', \n       'giCyVrdq', 'mHfYNU4q', 'aIoMYlV3', 'uQlfKROe', 'I5oCbFqU', '7OgaPmo8', 'vj28RUg0', \n       'woXyHNBr', '1tg3UJzG', '8YdaZ4eg', 'JHPfbgZ1', 'EZtGMeKm', 'IBREqrit', 'AsvqxgdU', \n       '9uAJinrI', 'Y1UQOByn', 'HcvGebr6', 'eSNJug3G', 'DkEa54bn', '7MuzF8Jo', 'Prp3YHoc', \n       'czAWLEuk', 'xSKstlN5', '8wUj4LGF', 'ZOyuld3U', 'YD843Ie1', 'rOsZ6xkQ', 'AFnBGQxE', \n       '2oStKrL7', 'SVANfGvI', '4CHUDKzQ', 'SkQCVrph', 'RFkVy6Gj', '4mLYGO6d', 'pNxEIa3i', \n       'k75ryC6E', 'rxoYgBcR', 'GzBKCNR0', 'Em0SdZCe', 'mKJgMDXv', 'tJEHCumY', 'k8GvsIxa', \n       'j8Tva0NC', 'sAKrHTBI', 'dOWsq3vQ', 'YEujDO49', '3SG49MKN', 'syfj72xE', 'LU1ds5P8', \n       'bR4NVhar', '5Sh31xmN', '7W9Jlwuv', 'c6kBh3nz', '4gPTaXJL', 'IVEd5SkM', 'ws5e0a8P', \n       've8BJ6s2', 'wzdFr0tP', 'TSCyFdqQ', 'FzAMfXcG', 'VheAb4kO', 'OUr5LnIC', '8otET1bP', \n       'oydxFsAD', 'xe3hz1UY', 'r1ZlYvpc', 'cm9EwQU2', 'AaukyJBU', '3j1upsIN', 'as7yltQJ', \n       'DUsu0zkH', 'u0Yz9rLJ', 'wbnUqQ2F', '3SJyhx2F', 'C3J8Oxnm', 'nsEwXu9k', 'MID0U1ZA', \n       'ykDaABeX', 'uz2f68hU', 'yc2EaZDJ', 'pNdxJnEf', 'Hv3UGPRz', 'Iw0ZfpKo', 'mUIVcqtR', \n       'm31I6cTD', 'Ow1Mhkaz', 'uSax3LOe', 'Ya50IKc9', '6LmHdbxa', 'PcH8M9RZ', '0i8TdrFw', \n       'rcutHBE9', 'uSVopLri', 'U96nNGkR', 'LkXRnEb6', '03FybMPz', 'Rdovw3C7', 'c2BnqCDT', \n       'KoMZHsqi', 'hFZCYHcM', 'yg4efXuG', 'BrMu6zV3', 'S7V4hIkY', 'vshEicrn', '4NGKAxBl', \n       'XEMtsYgn', 'XbLPHB76', '16bSkcB5', '1NnUGFwv', 'AG48trWL', 'a4b51Jfm', 'hyZK9XWP', \n       'aLBmP1ze', 'ipjQDwJf', 'YTjfkobL', 'Vdo50vyP', 'wjcFO1Nq', 'NhOsqela', 'LQomklIJ', \n       'KFUX4n0y', 'h8Rtvk3X', 'HYWLzKon', '3ef0KwqV', 'DpgEkYyX', '4U7SyvOx', 'etGDaAw7', \n       '8JhWU6ST', 'mjHPMUZ3', 'XTlaGDng', 'WU2zRqpH', 'SDwk2G1x', '6Ea5ckqf', '7Wy1hHl5']","execution_count":10},{"metadata":{"id":"65612BF9622F4281A2F5AAB71B7C8717","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 读取数据集\n# all_knowledge.csv\ndf_knowledge = pd.read_csv(os.path.join(data_path, 'all_knowledge.csv'))\n        \n# 对 section category knowledge_point 赋予课程之间唯一标示\ndf_knowledge['section'] = df_knowledge['course'] + df_knowledge['section']\ndf_knowledge['category'] = df_knowledge['course'] + df_knowledge['category']\ndf_knowledge['knowledge_point'] = df_knowledge['course'] + df_knowledge['knowledge_point']\n\n# course.csv\ndf_course = pd.read_csv(os.path.join(data_path, 'course.csv'))\n\n# student.csv\ndf_student = pd.read_csv(os.path.join(data_path, 'student.csv'))\n    \n# submission_s2.csv\ndf_test_score = pd.read_csv(os.path.join(data_path, 'submission_s2.csv'))\ndf_test_score.rename(columns={'pred': 'score'}, inplace=True)\n\n# exam_score.csv\ndf_train_score = pd.read_csv(os.path.join(data_path, 'exam_score.csv'))#全量\n#去除零异常值\ndf_train_score = df_train_score[df_train_score.score != 0]\n\ndf_train_score_jiajie = df_train_score[~df_train_score.exam_id.isin(ids)]#前三年\ndf_train_score = df_train_score[df_train_score.exam_id.isin(ids)]#最后一年\n\n\n\n# course1_exams.csv ~ course8_exams.csv\ndf_list = []\ndf_exams_order_list = []\nfor i in range(1, 9):\n    df_exams = pd.read_csv(os.path.join(data_path, 'course{}_exams.csv'.format(i)))\n    df_exams_order = df_exams[['exam_id']]\n    df_exams_order['order'] = df_exams.index\n    df_exams_order_list.append(df_exams_order)\n\n    del (df_exams_order)\n    gc.collect()\n\n    df_exams.set_index('exam_id', inplace=True)\n    df_exams = df_exams.stack().to_frame()\n    df_exams.reset_index(inplace=True)\n    df_exams.rename(columns={\n            'level_1': 'knowledge_point',\n            0: 'ratio'\n    },inplace=True)\n    df_exams['knowledge_point'] = 'course{}'.format(i) + df_exams['knowledge_point']\n\n    df_list.append(df_exams)\n\ndf_exams_ratio = pd.concat(df_list, axis=0)\ndf_exams_orders = pd.concat(df_exams_order_list, axis=0)","execution_count":11},{"metadata":{"id":"848751CEE30940BFA9780927914CF699","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 特征表\ndf_feature = pd.concat([df_train_score, df_test_score])#最后一年特征表\n#前三年特征只需要统计train中的就行，不需要统计和test合并\ndf_train_score_jiajie_feature=df_train_score_jiajie.copy()","execution_count":12},{"metadata":{"id":"7295555FFA6746DDB4F318800338468A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# ******* 学生特征 ******** #\n# 成绩 max mean std cv\ndf_feature = stat(df_train_score, df_feature, ['student_id'], {'score': ['max', 'mean', 'std', 'median']})\ndf_feature = stat_cv(df_train_score, df_feature, ['student_id'], 'score')\n\n#前三年\ndf_train_score_jiajie_feature = stat(df_train_score_jiajie, df_train_score_jiajie_feature, ['student_id'], {'score': ['max', 'mean', 'std', 'median']})\ndf_train_score_jiajie_feature = stat_cv(df_train_score_jiajie, df_train_score_jiajie_feature, ['student_id'], 'score')","execution_count":13},{"metadata":{"id":"DDD29F9FB80F4D819958F1A8A1A538F7","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# mean(个人考试成绩 / 本次考试平均成绩)\ndf_feature = stat_ratio_mean(df_train_score, df_feature, ['student_id'])\n\n#前三年\ndf_train_score_jiajie_feature = stat_ratio_mean(df_train_score_jiajie, df_train_score_jiajie_feature, ['student_id'])","execution_count":14},{"metadata":{"id":"DBFD893887A34CFEBB301F63962E3820","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 平均排名\ndf_feature = stat_rank(df_train_score, df_feature, ['student_id'])\n#前三年\ndf_train_score_jiajie_feature = stat_rank(df_train_score_jiajie, df_train_score_jiajie_feature, ['student_id'])","execution_count":15},{"metadata":{"id":"C027100F7AA74B82810F51A99DC7B98D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 性别\ndf_feature = df_feature.merge(df_student, on='student_id', how='left')\n\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_student, on='student_id', how='left')","execution_count":16},{"metadata":{"id":"F0FD040FF55D4E61A83EF3EFFB384A2D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# score / 难度 衡量学生抗压能力\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_course_exam_feature['complexity_ratio'] = df_course_exam_feature['ratio'] * df_course_exam_feature['complexity'] * 0.01\n\n\ndf_exam_complexity_sum = df_course_exam_feature.groupby(['exam_id'])['complexity_ratio'].sum().reset_index()\ndf_exam_complexity_sum.rename(columns={'complexity_ratio': 'exam_complexity'}, inplace=True)\n\ndf_score_complexity = df_train_score.merge(df_exam_complexity_sum, on='exam_id', how='left')\ndf_score_complexity_1 = df_train_score_jiajie.merge(df_exam_complexity_sum, on='exam_id', how='left')\n\n\ndf_score_complexity.drop_duplicates(inplace=True)\ndf_score_complexity_1.drop_duplicates(inplace=True)\n\n\ndf_score_complexity['s/c'] = df_score_complexity['score'] / df_score_complexity['exam_complexity']\ndf_score_complexity_1['s/c'] = df_score_complexity_1['score'] / df_score_complexity_1['exam_complexity']\n\n\n\ndf_feature = stat(df_score_complexity, df_feature, ['student_id'], {'s/c': ['mean', 'std', 'max', 'median']})\ndf_feature = stat(df_score_complexity, df_feature, ['student_id', 'course'], {'s/c': ['mean', 'std', 'max', 'median']})\ndf_feature = stat_cv(df_score_complexity, df_feature, ['student_id', 'course'], 's/c')\ndf_feature = stat_cv(df_score_complexity, df_feature, ['student_id'], 's/c')\n#前三年\ndf_train_score_jiajie_feature = stat(df_score_complexity_1, df_train_score_jiajie_feature, ['student_id'], {'s/c': ['mean', 'std', 'max', 'median']})\ndf_train_score_jiajie_feature = stat(df_score_complexity_1, df_train_score_jiajie_feature, ['student_id', 'course'], {'s/c': ['mean', 'std', 'max', 'median']})\ndf_train_score_jiajie_feature = stat_cv(df_score_complexity_1, df_train_score_jiajie_feature, ['student_id', 'course'], 's/c')\ndf_train_score_jiajie_feature = stat_cv(df_score_complexity_1, df_train_score_jiajie_feature, ['student_id'], 's/c')\n\n\n\n\ndel (df_score_complexity)\ndel (df_score_complexity_1)\ndel (df_course_exam_feature)\ndel (df_exam_complexity_sum)\ngc.collect()\n","execution_count":17},{"metadata":{"id":"2AFAC4CE4C5C4AAABAAB098E4D6D33DA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# ******* 考试特征 ******** #\n# 考试次序\ndf_feature = df_feature.merge(df_exams_orders, how='left')\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_exams_orders, how='left')\n","execution_count":18},{"metadata":{"id":"103FCB61BF874A2099C9148B1CEC092E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 考试知识点范围（不为0个数/总个数）\ndf_temp = df_exams_ratio.groupby(['exam_id'])['ratio'].apply(lambda x: (x != 0).sum() / x.shape[\n            0]).reset_index().rename(columns={'ratio': 'exam_kp_range'})\ndf_feature = df_feature.merge(df_temp, on='exam_id', how='left')\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_temp, on='exam_id', how='left')\n\n\ndel (df_temp)\ngc.collect()","execution_count":19},{"metadata":{"id":"E5225610F66346CF894BE92054F4AAB2","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 考试的知识点占比\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'knowledge_point', 'ratio']]\np = gen_feature(df_temp, 'exam_id', 'knowledge_point', 'ratio')\ndf_sparse_f = p.drop(['exam_id'], axis=1)\ndf_exam_f = p[['exam_id']]\npca = PCA(n_components=dimension, random_state=seed)\ndf_no_sparse_f = pd.DataFrame(pca.fit_transform(df_sparse_f))\ndf_no_sparse_f.columns = [ 'exam_point_ratio' + str(c) for c in df_no_sparse_f.columns]\ndf_exam_f = pd.concat([df_exam_f, df_no_sparse_f], axis=1)\ndf_feature = df_feature.merge(df_exam_f, on='exam_id', how='left')\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_exam_f, on='exam_id', how='left')\n\ndel (df_course_exam_feature)\ndel (df_temp)\ndel (df_sparse_f)\ndel (df_exam_f)\ndel (df_no_sparse_f)\ndel (p)\ngc.collect()\n\ndf_feature.shape","execution_count":20},{"metadata":{"id":"38A4C93D208741148795BC7E0A647CCB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 考试各段落和种类占比\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'section', 'category', 'ratio']]\n\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'section'], {'ratio': ['sum']})\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'category'], {'ratio': ['sum']})\n\ndf_exam_f = df_temp[['exam_id']]\ndf_exam_f.drop_duplicates(inplace=True)\np = gen_feature(df_temp, 'exam_id', 'section', 'exam_id_section_ratio_sum')\ndf_exam_f = df_exam_f.merge(p, on='exam_id', how='left')\np = gen_feature(df_temp, 'exam_id', 'category', 'exam_id_category_ratio_sum')\ndf_exam_f = df_exam_f.merge(p, on='exam_id', how='left')\n\ndf_sparse_f = df_exam_f.drop(['exam_id'], axis=1)\ndf_exam_f = df_exam_f[['exam_id']]\npca = PCA(n_components=dimension, random_state=seed)\ndf_no_sparse_f = pd.DataFrame(pca.fit_transform(df_sparse_f))\ndf_no_sparse_f.columns = [\n    'exam_section_cat_ratio' + str(c) for c in df_no_sparse_f.columns\n]\ndf_exam_f = pd.concat([df_exam_f, df_no_sparse_f], axis=1)\ndf_feature = df_feature.merge(df_exam_f, on='exam_id', how='left')\n\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_exam_f, on='exam_id', how='left')\n\ndel (df_course_exam_feature)\ndel (df_temp)\ndel (df_sparse_f)\ndel (df_exam_f)\ndel (df_no_sparse_f)\ndel (p)\ngc.collect()\n","execution_count":21},{"metadata":{"id":"3910D27ECB4149CE8C0B83ADE6016876","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 考试的各难度占比\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                                  on=['knowledge_point'],\n                                                  how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'complexity', 'ratio']]\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'complexity'], {'ratio': ['sum']})\np = gen_feature(df_temp, 'exam_id', 'complexity', 'exam_id_complexity_ratio_sum')\ndf_feature = df_feature.merge(p, on='exam_id', how='left')\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(p, on='exam_id', how='left')\n\ndel (df_course_exam_feature)\ndel (df_temp)\ndel (p)\ngc.collect()\n\ndf_feature.shape","execution_count":22},{"metadata":{"id":"145464B3317448CAAA56B1B6C42A6AA1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 考试总体难度\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_course_exam_feature['complexity_ratio'] = df_course_exam_feature['ratio'] * df_course_exam_feature['complexity'] * 0.01\ndf_exam_complexity_sum = df_course_exam_feature.groupby(['exam_id'])['complexity_ratio'].sum().reset_index()\ndf_exam_complexity_sum.rename(columns={'complexity_ratio': 'exam_complexity'}, inplace=True)\ndf_feature = df_feature.merge(df_exam_complexity_sum, on='exam_id',  how='left')\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_exam_complexity_sum, on='exam_id',  how='left')\n\ndel (df_course_exam_feature)\ndel (df_exam_complexity_sum)\ngc.collect()\n\ndf_feature.shape","execution_count":23},{"metadata":{"id":"CB6D1EF5126F4350BC3FFA4717B6B55F","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 针对考试知识点的有无构建句子，使用 w2v 为考试学习低维表示\nfrom gensim.models.word2vec import Word2Vec \n\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'knowledge_point', 'ratio']]\ndf_temp = df_temp[df_temp.ratio != 0]\n\nsentences = []\n# 这边没去重， 句子会有重复\nkps = df_temp['knowledge_point'].values\nexam_ids = list(set(df_temp['exam_id'].values))\n\nfor kp in kps:\n    df_kp = df_temp[df_temp.knowledge_point == kp]\n    sentence = df_kp['exam_id'].values\n    sentences.append(list(set(sentence)))\n\nmodel= Word2Vec(size=dimension,window=2, min_count=1,iter=10)\nmodel.build_vocab(sentences)\nmodel.train(sentences, total_examples = model.corpus_count, epochs = model.iter)\n\nembds = []\nfor exam_id in exam_ids:\n    embd = model[exam_id]\n    embds.append(embd)\ndf_temp = pd.DataFrame(embds)\ndf_temp.columns = ['w2v'+str(f) for f in df_temp.columns]\ndf_temp['exam_id'] = exam_ids\n\ndf_feature = df_feature.merge(df_temp, on='exam_id',  how='left')\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_temp, on='exam_id',  how='left')\n\ndel df_temp\ngc.collect()","execution_count":26},{"metadata":{"id":"81E664B524F049AF8C5DB4747253BC5C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# ******* 课程特征 ******** #\n# max mean std cv\ndf_feature = stat(df_train_score, df_feature, ['course'], {'score': ['mean', 'std', 'median']})\ndf_feature = stat_cv(df_train_score, df_feature, ['course'], 'score')\n\ndf_train_score_jiajie_feature = stat(df_train_score_jiajie, df_train_score_jiajie_feature, ['course'], {'score': ['mean', 'std', 'median']})\ndf_train_score_jiajie_feature = stat_cv(df_train_score_jiajie, df_train_score_jiajie_feature, ['course'], 'score')","execution_count":27},{"metadata":{"id":"A6D4D5771FBF437C8C690735BF349050","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# course_class 属性\ndf_feature = df_feature.merge(df_course, on='course', how='left')\n#前三年\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_course, on='course', how='left')","execution_count":28},{"metadata":{"id":"195B59F1F7804D79883C11967858330E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# ******* 学生，考试组合特征 ******** #\n# 学生在各个知识点上得分\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'knowledge_point', 'ratio']]\ndf_temp = df_temp[df_temp.ratio != 0]\ndf_temp = df_train_score.merge(df_temp, on='exam_id', how='left')\n\n\n\n\ndf_temp.drop(['exam_id', 'course'], axis=1, inplace=True)\ndf_temp['point_score'] = df_temp['ratio'] * df_temp['score'] * 0.01\ng = df_temp.groupby(['student_id', 'knowledge_point'])['point_score'].agg({\n    'student_point_score_mean':\n    'mean',\n})\ng.reset_index(inplace=True)\np = gen_feature(g, 'student_id', 'knowledge_point', 'student_point_score_mean')\ndf_sparse_f = p.drop(['student_id'], axis=1)\ndf_student_f = p[['student_id']]\npca = PCA(n_components=dimension, random_state=seed)\ndf_no_sparse_f = pd.DataFrame(pca.fit_transform(df_sparse_f))\ndf_no_sparse_f.columns = [\n    's_point_score' + str(c) for c in df_no_sparse_f.columns\n]\ndf_student_f = pd.concat([df_student_f, df_no_sparse_f], axis=1)\ndf_feature = df_feature.merge(df_student_f, on='student_id', how='left')\n\n\n\ndel (df_course_exam_feature)\ndel (df_temp)\ndel (df_sparse_f)\ndel (df_student_f)\ndel (df_no_sparse_f)\ndel (g)\ndel (p)\ngc.collect()\n\ndf_feature.shape","execution_count":29},{"metadata":{"id":"5C8085B89CCB45CDBF61B317820C669A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# ******* 学生，考试组合特征 ******** #\n# 学生在各个知识点上得分\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'knowledge_point', 'ratio']]\ndf_temp = df_temp[df_temp.ratio != 0]\ndf_temp = df_train_score_jiajie.merge(df_temp, on='exam_id', how='left')\n\n\n\n\ndf_temp.drop(['exam_id', 'course'], axis=1, inplace=True)\ndf_temp['point_score'] = df_temp['ratio'] * df_temp['score'] * 0.01\ng = df_temp.groupby(['student_id', 'knowledge_point'])['point_score'].agg({\n    'student_point_score_mean':\n    'mean',\n})\ng.reset_index(inplace=True)\np = gen_feature(g, 'student_id', 'knowledge_point', 'student_point_score_mean')\ndf_sparse_f = p.drop(['student_id'], axis=1)\ndf_student_f = p[['student_id']]\npca = PCA(n_components=dimension, random_state=seed)\ndf_no_sparse_f = pd.DataFrame(pca.fit_transform(df_sparse_f))\ndf_no_sparse_f.columns = [\n    's_point_score' + str(c) for c in df_no_sparse_f.columns\n]\ndf_student_f = pd.concat([df_student_f, df_no_sparse_f], axis=1)\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_student_f, on='student_id', how='left')\n\n\n\ndel (df_course_exam_feature)\ndel (df_temp)\ndel (df_sparse_f)\ndel (df_student_f)\ndel (df_no_sparse_f)\ndel (g)\ndel (p)\ngc.collect()\n\ndf_train_score_jiajie_feature.shape","execution_count":30},{"metadata":{"id":"B619227F8D1140228CA5920BBABBA5BD","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 学生在各个section category上的平均得分（是否需要保留，后期测试）\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'section', 'category', 'ratio']]\ndf_temp = df_temp[df_temp.ratio != 0]\n\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'section'], {'ratio': ['sum']})\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'category'], {'ratio': ['sum']})\n\ndf_temp_section = df_temp[[\n    'exam_id',\n    'section',\n    'exam_id_section_ratio_sum',\n]]\ndf_temp_category = df_temp[[\n    'exam_id', 'category', 'exam_id_category_ratio_sum'\n]]\n\ndf_temp_section.drop_duplicates(inplace=True)\ndf_temp_category.drop_duplicates(inplace=True)\n\ndf_temp_section = df_train_score.merge(df_temp_section,\n                                       on='exam_id',\n                                       how='left')\ndf_temp_category = df_train_score.merge(df_temp_category,\n                                        on='exam_id',\n                                        how='left')\n\ndf_temp_section['section_score'] = df_temp_section[\n    'exam_id_section_ratio_sum'] * df_temp_section['score'] * 0.01\ndf_temp_category['category_score'] = df_temp_category[\n    'exam_id_category_ratio_sum'] * df_temp_category['score'] * 0.01\n\ndf_temp_section = stat(df_temp_section,\n                       df_temp_section, ['student_id', 'section'],\n                       agg={'section_score': ['max', 'mean', 'std', 'median']})\ndf_temp_category = stat(df_temp_category, df_temp_category,\n                        ['student_id', 'category'],\n                        {'category_score': ['max', 'mean', 'std', 'median']})\n\ndf_student_f = df_temp_section[['student_id']]\ndf_student_f.drop_duplicates(inplace=True)\np = gen_feature(df_temp_section, 'student_id', 'section',\n                'student_id_section_section_score_mean')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\np = gen_feature(df_temp_section, 'student_id', 'section',\n                'student_id_section_section_score_max')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\np = gen_feature(df_temp_section, 'student_id', 'section',\n                'student_id_section_section_score_std')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\n\np = gen_feature(df_temp_category, 'student_id', 'category',\n                'student_id_category_category_score_mean')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\np = gen_feature(df_temp_category, 'student_id', 'category',\n                'student_id_category_category_score_max')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\np = gen_feature(df_temp_category, 'student_id', 'category',\n                'student_id_category_category_score_std')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\n\ndf_sparse_f = df_student_f.drop(['student_id'], axis=1)\ndf_student_f = df_student_f[['student_id']]\npca = PCA(n_components=dimension, random_state=seed)\ndf_no_sparse_f = pd.DataFrame(pca.fit_transform(df_sparse_f))\ndf_no_sparse_f.columns = [\n    'student_section_cat_score' + str(c) for c in df_no_sparse_f.columns\n]\ndf_student_f = pd.concat([df_student_f, df_no_sparse_f], axis=1)\ndf_feature = df_feature.merge(df_student_f, on='student_id', how='left')\n\ndel (df_temp)\ndel (df_course_exam_feature)\ndel (df_temp_section)\ndel (df_temp_category)\ndel (df_sparse_f)\ndel (df_no_sparse_f)\ndel (df_student_f)\ngc.collect()","execution_count":31},{"metadata":{"id":"5216CEF9AED94D96805B6393627D12B5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#前三年\n\n# 学生在各个section category上的平均得分（是否需要保留，后期测试）\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'section', 'category', 'ratio']]\ndf_temp = df_temp[df_temp.ratio != 0]\n\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'section'], {'ratio': ['sum']})\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'category'], {'ratio': ['sum']})\n\ndf_temp_section = df_temp[[\n    'exam_id',\n    'section',\n    'exam_id_section_ratio_sum',\n]]\ndf_temp_category = df_temp[[\n    'exam_id', 'category', 'exam_id_category_ratio_sum'\n]]\n\ndf_temp_section.drop_duplicates(inplace=True)\ndf_temp_category.drop_duplicates(inplace=True)\n\ndf_temp_section = df_train_score_jiajie.merge(df_temp_section,\n                                       on='exam_id',\n                                       how='left')\ndf_temp_category = df_train_score_jiajie.merge(df_temp_category,\n                                        on='exam_id',\n                                        how='left')\n\ndf_temp_section['section_score'] = df_temp_section[\n    'exam_id_section_ratio_sum'] * df_temp_section['score'] * 0.01\ndf_temp_category['category_score'] = df_temp_category[\n    'exam_id_category_ratio_sum'] * df_temp_category['score'] * 0.01\n\ndf_temp_section = stat(df_temp_section,\n                       df_temp_section, ['student_id', 'section'],\n                       agg={'section_score': ['max', 'mean', 'std', 'median']})\ndf_temp_category = stat(df_temp_category, df_temp_category,\n                        ['student_id', 'category'],\n                        {'category_score': ['max', 'mean', 'std', 'median']})\n\ndf_student_f = df_temp_section[['student_id']]\ndf_student_f.drop_duplicates(inplace=True)\np = gen_feature(df_temp_section, 'student_id', 'section',\n                'student_id_section_section_score_mean')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\np = gen_feature(df_temp_section, 'student_id', 'section',\n                'student_id_section_section_score_max')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\np = gen_feature(df_temp_section, 'student_id', 'section',\n                'student_id_section_section_score_std')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\n\np = gen_feature(df_temp_category, 'student_id', 'category',\n                'student_id_category_category_score_mean')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\np = gen_feature(df_temp_category, 'student_id', 'category',\n                'student_id_category_category_score_max')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\np = gen_feature(df_temp_category, 'student_id', 'category',\n                'student_id_category_category_score_std')\ndf_student_f = df_student_f.merge(p, on='student_id', how='left')\n\ndf_sparse_f = df_student_f.drop(['student_id'], axis=1)\ndf_student_f = df_student_f[['student_id']]\npca = PCA(n_components=dimension, random_state=seed)\ndf_no_sparse_f = pd.DataFrame(pca.fit_transform(df_sparse_f))\ndf_no_sparse_f.columns = [\n    'student_section_cat_score' + str(c) for c in df_no_sparse_f.columns\n]\ndf_student_f = pd.concat([df_student_f, df_no_sparse_f], axis=1)\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_student_f, on='student_id', how='left')\n\ndel (df_temp)\ndel (df_course_exam_feature)\ndel (df_temp_section)\ndel (df_temp_category)\ndel (df_sparse_f)\ndel (df_no_sparse_f)\ndel (df_student_f)\ngc.collect()","execution_count":32},{"metadata":{"id":"FD8FB9D193E5498C8DD88A7917C2E432","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# ******* 学生，课程组合特征 ******** #\n# max mean std cv\ndf_feature = stat(df_train_score, df_feature, ['student_id', 'course'],\n                      {'score': ['max', 'mean', 'std', 'median']})\ndf_feature = stat_cv(df_train_score, df_feature, ['student_id', 'course'],\n                         'score')\n\n\n#前三年\n\ndf_train_score_jiajie_feature = stat(df_train_score_jiajie, df_train_score_jiajie_feature, ['student_id', 'course'],\n                      {'score': ['max', 'mean', 'std', 'median']})\ndf_train_score_jiajie_feature = stat_cv(df_train_score_jiajie, df_train_score_jiajie_feature, ['student_id', 'course'],\n                         'score')","execution_count":33},{"metadata":{"id":"3D59C6A5D85E485E8899059EB6C6F799","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 课程平均排名\ndf_feature = stat_rank(df_train_score, df_feature, ['student_id', 'course'])\n#前三年\ndf_train_score_jiajie_feature = stat_rank(df_train_score_jiajie, df_train_score_jiajie_feature, ['student_id', 'course'])","execution_count":34},{"metadata":{"id":"529C9F04998F4E088368D9D7B7CBB1CA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 课程平均分\ndf_feature = stat_ratio_mean(df_train_score, df_feature, ['student_id', 'course'])\n#前三年\ndf_train_score_jiajie_feature = stat_ratio_mean(df_train_score_jiajie, df_train_score_jiajie_feature, ['student_id', 'course'])","execution_count":35},{"metadata":{"id":"AE99C77734F848CF85B1C00ED6A420E9","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 性别在课程考试 max mean std cv\ndf_feature = stat(df_feature, df_feature, ['gender', 'course'],\n                      {'score': ['mean', 'std', 'median']})\ndf_feature = stat_cv(df_feature, df_feature, ['gender', 'course'], 'score')\n\n\n#前三年\ndf_train_score_jiajie_feature = stat(df_train_score_jiajie_feature, df_train_score_jiajie_feature, ['gender', 'course'],\n                      {'score': ['mean', 'std', 'median']})\ndf_train_score_jiajie_feature = stat_cv(df_train_score_jiajie_feature, df_train_score_jiajie_feature, ['gender', 'course'], 'score')","execution_count":36},{"metadata":{"id":"4E150DC5A36B42008BDCBD242661DFF7","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 学生课程最近三次考试平均成绩\ndf_score = pd.concat([df_train_score, df_test_score])\ndf_temp = df_score.merge(df_exams_orders, how='left')\ndf_temp.sort_values(['student_id', 'course', 'order'], inplace=True)\ndf_temp['pre_3_score_mean'] = df_temp.groupby(\n        ['student_id',\n         'course'])['score'].shift(1).rolling(window=3, min_periods=1).mean()\n# df_temp['pre_3_score_std'] = df_temp.groupby(\n#         ['student_id',\n#          'course'])['score'].shift(1).rolling(window=3, min_periods=1).std()\n# df_temp['pre_3_score_diff_mean'] = df_temp.groupby(\n#         ['student_id',\n#          'course'])['score'].shift(1).diff().rolling(window=3, min_periods=1).mean()\ndf_temp = df_temp[['student_id', 'course', 'exam_id', 'pre_3_score_mean']]\ndf_feature = df_feature.merge(df_temp,\n                                   on=['student_id', 'course', 'exam_id'],\n                                   how='left')\ndel (df_score)\ndel (df_temp)\ngc.collect()","execution_count":37},{"metadata":{"id":"3FCD71858E2541ABBD6C5016522617F5","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#前三年\n# 学生课程最近三次考试平均成绩\n# df_score = pd.concat([df_train_score, df_test_score])\ndf_temp = df_train_score_jiajie.merge(df_exams_orders, how='left')\ndf_temp.sort_values(['student_id', 'course', 'order'], inplace=True)\ndf_temp['pre_3_score_mean'] = df_temp.groupby(\n        ['student_id',\n         'course'])['score'].shift(1).rolling(window=3, min_periods=1).mean()\ndf_temp = df_temp[['student_id', 'course', 'exam_id', 'pre_3_score_mean']]\ndf_train_score_jiajie_feature = df_train_score_jiajie_feature.merge(df_temp,\n                                   on=['student_id', 'course', 'exam_id'],\n                                   how='left')\ndel (df_temp)\ngc.collect()","execution_count":38},{"metadata":{"id":"CED915C6E7DE42808318CC6407115241","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# LabelEncoder\nfor f in ['course', 'course_class']:\n    lbl = LabelEncoder()\n    df_feature[f] = lbl.fit_transform(df_feature[f].astype(str))\n    df_train_score_jiajie_feature[f] = lbl.fit_transform(df_train_score_jiajie_feature[f].astype(str))","execution_count":39},{"metadata":{"id":"85746338578E466C8B782BC811AAAA09","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#在这里应该合并df_feature 和df_train_score_jiajie_feature\nlen_dfeature=df_feature.shape[0]\nfeature=df_feature.append(df_train_score_jiajie_feature).reset_index(drop=True)","execution_count":40},{"metadata":{"id":"388A7F2A256A46D38A134C2C64E85DE1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"feature = select_feature(feature)","execution_count":41},{"metadata":{"id":"C186D99BDA9E45D382FBCCF760383FE8","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_feature=feature[:len_dfeature]#最后一年\ndf_jiajie=feature[len_dfeature:]#前三年","execution_count":42},{"metadata":{"id":"A00E038769124720B73A8546E826059C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"#构造嫁接学习model，然后用model取预测最后一年的分数作为最后一模型的feature\n\nimport matplotlib.pyplot as plt\n\nseed = 2008\nnfold = 5\n\nycol = 'score'\n\nfeature_names = list(\n    filter(lambda x: x not in [ycol, 'student_id','exam_id'], df_jiajie.columns))\n\njiajie_pred = np.zeros((df_feature.shape[0],))\nkfolder = KFold(n_splits=nfold, shuffle=True, random_state=seed)\ndf_val_list = []\nscore_train_total = 0\nscore_val_total = 0\nfor fold_id, (trn_idx, val_idx) in enumerate(kfolder.split(df_jiajie)):\n    print(\n        '\\nxgboost Fold_{} Training ================================\\n'.format(\n            fold_id+1))\n    X_train = df_jiajie.iloc[trn_idx][feature_names]\n    Y_train = df_jiajie.iloc[trn_idx][ycol]\n\n    X_val = df_jiajie.iloc[val_idx][feature_names]\n    Y_val = df_jiajie.iloc[val_idx][ycol]\n\n    jiajie_model = xgb.XGBRegressor(random_state=seed,\n                                 max_depth=8,\n                                 n_estimators=10000,\n                                 min_child_weight=300,\n                                 colsample_bytree=0.8,\n                                 subsample=0.8,\n                                 learning_rate=0.1,\n                                 reg_alpha=1,\n                                 reg_lambda=0.8,\n                                 objective=\"reg:linear\",\n                                 eta=0.1)\n\n    jiajie_model.fit(X_train,\n                  Y_train,\n                  eval_set=[(X_train, Y_train), (X_val, Y_val)],\n                  verbose=1000,\n                  early_stopping_rounds=500,\n                  eval_metric='rmse')\n\n\n    jiajie_pred += jiajie_model.predict(df_feature[feature_names]) / nfold","execution_count":43},{"metadata":{"id":"00360B0EFA514A5B940D67DA7A94A30E","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_feature['jiajie_pred_score']=jiajie_pred","execution_count":44},{"metadata":{"id":"58485F0604174BB3B12FF08AF892AF39","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_feature[['jiajie_pred_score', 'exam_id','student_id']].to_csv(os.path.join(current_path, 'jiajie.csv'),index=False)","execution_count":45},{"metadata":{"id":"BD57D935E4124292BEF3F9B7AF955805","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_feature.head()","execution_count":null}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}