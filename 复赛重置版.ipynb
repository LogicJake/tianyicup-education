{"cells":[{"metadata":{"id":"474D5A2C75114739812F1ACE4BA142F4","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import gc\nimport os\nimport sys\nimport warnings\n\nimport numpy as np\nimport pandas as pd\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.decomposition import PCA\nfrom sklearn.feature_selection import SelectPercentile, f_classif, chi2\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import Binarizer, LabelEncoder, scale\nfrom sklearn.neighbors import NearestNeighbors\n\nwarnings.filterwarnings('ignore')","execution_count":3},{"metadata":{"id":"FCD449C5384845E88D16C24736C745AB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 数据目录\ndata_path = '/home/kesci/input/smart_edu7557'\n# 工作目录\ncurrent_path = '/home/kesci/work'","execution_count":4},{"metadata":{"id":"639A7EBE7F06456688A349288885273B","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 简单统计\ndef stat(df, df_merge, group_by, agg):\n    group = df.groupby(group_by).agg(agg)\n\n    columns = []\n    for on, methods in agg.items():\n        for method in methods:\n            columns.append('{}_{}_{}'.format('_'.join(group_by), on, method))\n    group.columns = columns\n    group.reset_index(inplace=True)\n    df_merge = df_merge.merge(group, on=group_by, how='left')\n\n    del (group)\n    gc.collect()\n    return df_merge","execution_count":5},{"metadata":{"id":"2A629301E7664EFABDD573CF2D00AED4","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# cv 统计\ndef stat_cv(df, df_merge, group_by, on):\n    group = df.groupby(group_by).agg({on: ['std', 'mean']})\n    group.columns = ['std', 'mean']\n    group.reset_index(inplace=True)\n\n    group['cv'] = group['std'] / group['mean']\n    group.drop(['std', 'mean'], axis=1, inplace=True)\n\n    group.columns = group_by + ['{}_{}_cv'.format('_'.join(group_by), on)]\n    df_merge = df_merge.merge(group, on=group_by, how='left')\n\n    del (group)\n    gc.collect()\n    return df_merge","execution_count":6},{"metadata":{"id":"8D94C62578534F5D852FB51ADFE40CC6","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# rank 统计\ndef stat_rank(df, df_merge, group_by):\n    df_temp = df.copy(deep=True)\n    df_temp['rank'] = df.groupby(['exam_id'])['score'].rank(method='min',\n                                                            ascending=False)\n    methods = ['mean', 'std', 'max', 'min']\n    df_temp = df_temp.groupby(group_by).agg({'rank': methods})\n    \n    columns = []\n    for method in methods:\n        columns.append('{}_rank_{}'.format('_'.join(group_by), method))\n    df_temp.columns = columns\n    df_temp.reset_index(inplace=True)\n\n    df_merge = df_merge.merge(df_temp, how='left')\n    return df_merge","execution_count":7},{"metadata":{"id":"E08E610B7E3843749C853F2FFADDDED0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# student score mean / exam mean score\ndef stat_ratio_mean(df, df_merge, group_by):\n    df_temp = df.copy(deep=True)\n    df_temp['exam_mean_score'] = df.groupby(['exam_id'\n                                             ])['score'].transform('mean')\n    df_temp['student_score_ratio_exam_mean_score'] = df_temp[\n        'score'] / df_temp['exam_mean_score']\n\n    df_temp = df_temp.groupby(\n        group_by)['student_score_ratio_exam_mean_score'].mean().to_frame()\n    df_temp.reset_index(inplace=True)\n    df_temp.columns = group_by + [\n        'student_score_exam_mean_score_ratio_{}_mean'.format(\n            '_'.join(group_by))\n    ]\n\n    df_merge = df_merge.merge(df_temp, how='left')\n    return df_merge","execution_count":8},{"metadata":{"id":"120C8057898A48FE9575B58E96A1AE09","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# time_feature\ndef stat_time(df, df_merge, window, group_by, on, method):\n    df_temp = df.copy(deep=True)\n    \n    name = 'pre_{}_{}_{}'.format(window, on, method)\n    \n    df_temp.sort_values(group_by+['order'], inplace=True)\n    df_temp[name] = df_temp.groupby(group_by).shift(1).rolling(window=window, min_periods=1).agg({on: method})\n    \n    df_temp = df_temp[group_by+['order', name]]\n    df_merge = df_merge.merge(df_temp, on=group_by+['order'], how='left')\n    return df_merge","execution_count":9},{"metadata":{"id":"EEEE64299C244DA18E253C4446BED02A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def gen_feature(df, index, columns, values):\n    p = df.pivot_table(index=index, columns=columns,\n                       values=values).reset_index().fillna(0)\n    columns = p.columns.values.tolist()\n    columns = ['{}_{}'.format(c, values) if c != index else c for c in columns]\n    p.columns = columns\n\n    return p","execution_count":10},{"metadata":{"id":"902A9142CFB142168B0951C15C524F2D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def select_feature(df):\n    p = 86\n\n    df.fillna(0, inplace=True)\n    ycol = 'score'\n    feature_names = [f for f in df.columns if f not in [ycol, 'student_id', 'course', 'exam_id']]\n\n    X = df[feature_names]\n    Y = df[ycol]\n    X_bin = Binarizer().fit_transform(scale(X))\n\n    selectChi2 = SelectPercentile(chi2, percentile=p).fit(X_bin, Y)\n    selectF_classif = SelectPercentile(f_classif, percentile=p).fit(X, Y)\n\n    chi2_selected = selectChi2.get_support()\n    print('Chi2 selected {} features.'.format(chi2_selected.sum()))\n    f_classif_selected = selectF_classif.get_support()\n    print('F_classif selected {} features.'.format(f_classif_selected.sum()))\n    selected = chi2_selected & f_classif_selected\n    print('Chi2 & F_classif selected {} features'.format(selected.sum()))\n    features = [f for f, s in zip(feature_names, selected) if s]\n\n    x = list(set(feature_names) - set(features))\n    x.sort()\n    print(x)\n    df_sel = df[features]\n    df_basic = df[[ycol, 'student_id', 'course', 'exam_id']]\n    df_sel = pd.concat([df_sel, df_basic], axis=1)\n    return df_sel","execution_count":11},{"metadata":{"id":"4A7F72A137284D6687C943379EF506F1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 读取数据集\n# all_knowledge.csv\ndf_knowledge = pd.read_csv(os.path.join(data_path, 'all_knowledge.csv'))\n        \n# 对 section category knowledge_point 赋予课程之间唯一标示\ndf_knowledge['section'] = df_knowledge['course'] + df_knowledge['section']\ndf_knowledge['category'] = df_knowledge['course'] + df_knowledge['category']\ndf_knowledge['knowledge_point'] = df_knowledge['course'] + df_knowledge['knowledge_point']\n\n# course.csv\ndf_course = pd.read_csv(os.path.join(data_path, 'course.csv'))\n\n# student.csv\ndf_student = pd.read_csv(os.path.join(data_path, 'student.csv'))\n    \n# submission_s2.csv\ndf_test_score = pd.read_csv(os.path.join(data_path, 'submission_s2.csv'))\ndf_test_score.rename(columns={'pred': 'score'}, inplace=True)\n\n# exam_score.csv\ndf_train_score_all = pd.read_csv(os.path.join(data_path, 'exam_score.csv'))\n\n# 去掉 0 分数\ndf_train_score = df_train_score_all[df_train_score_all.score != 0]\n\n# course1_exams.csv ~ course8_exams.csv\ndf_list = []\ndf_exams_order_list = []\nfor i in range(1, 9):\n    df_exams = pd.read_csv(os.path.join(data_path, 'course{}_exams.csv'.format(i)))\n    df_exams_order = df_exams[['exam_id']]\n    df_exams_order['order'] = df_exams.index\n    df_exams_order_list.append(df_exams_order)\n\n    del (df_exams_order)\n    gc.collect()\n\n    df_exams.set_index('exam_id', inplace=True)\n    df_exams = df_exams.stack().to_frame()\n    df_exams.reset_index(inplace=True)\n    df_exams.rename(columns={\n            'level_1': 'knowledge_point',\n            0: 'ratio'\n    },inplace=True)\n    df_exams['knowledge_point'] = 'course{}'.format(i) + df_exams['knowledge_point']\n\n    df_list.append(df_exams)\n\ndf_exams_ratio = pd.concat(df_list, axis=0)\ndf_exams_orders = pd.concat(df_exams_order_list, axis=0)","execution_count":12},{"metadata":{"id":"D0971BF53F3D472F826348A0CEB3A101","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 特征表\ndf_feature = pd.concat([df_train_score, df_test_score])","execution_count":13},{"metadata":{"id":"A8CC23524D884F3D831CEBE9A6B5B1B8","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 不涉及score的特征构造\n# 性别\ndf_feature = df_feature.merge(df_student, on='student_id', how='left')\n\n# 考试次序\ndf_feature = df_feature.merge(df_exams_orders, how='left')\n\n# 考试知识点数量\ndf_temp = df_exams_ratio.groupby(['exam_id'])['ratio'].apply(lambda x: (x != 0).sum() / x.shape[0]).\\\n        reset_index().rename(columns={'ratio': 'exam_kp_num'})\ndf_feature = df_feature.merge(df_temp, on='exam_id', how='left')\ndel (df_temp)\ngc.collect()\n\n# 考试知识点 max-min\ndf_temp = df_exams_ratio[df_exams_ratio.ratio != 0]\ndf_temp['kp'] = df_temp['knowledge_point'].str.split(':', expand=True)[1]\ndf_temp['kp'] = df_temp['kp'].astype('int')\ndf_temp['kp_max'] = df_temp.groupby(['exam_id'])['kp'].transform('max')\ndf_temp['kp_min'] = df_temp.groupby(['exam_id'])['kp'].transform('min')\ndf_temp['kp_range'] = df_temp['kp_max'] - df_temp['kp_min']\ndf_temp = df_temp[['exam_id', 'kp_range']].drop_duplicates()\ndf_feature = df_feature.merge(df_temp, on='exam_id', how='left')\ndel (df_temp)\ngc.collect()\n\n# 考试知识点section数量 (不为0 / 总个数)\ndf_temp = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'section'], {'ratio': ['sum']})\ndf_temp = df_temp[['exam_id', 'section', 'exam_id_section_ratio_sum']]\ndf_temp.drop_duplicates(inplace=True)\ndf_temp = df_temp.groupby(['exam_id'])['exam_id_section_ratio_sum'].\\\n            apply(lambda x: (x != 0).sum() / x.shape[0]).reset_index().rename(columns={'exam_id_section_ratio_sum': 'exam_section_num'})\ndf_feature = df_feature.merge(df_temp, on='exam_id', how='left')\ndel (df_temp)\ngc.collect()\n\n# 考试知识点section max-min\ndf_temp = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'section'], {'ratio': ['sum']})\ndf_temp = df_temp[['exam_id', 'section', 'exam_id_section_ratio_sum']]\ndf_temp.drop_duplicates(inplace=True)\ndf_temp = df_temp[df_temp.exam_id_section_ratio_sum != 0]\ndf_temp['sec'] = df_temp['section'].str.split(':', expand=True)[1]\ndf_temp['sec'] = df_temp['sec'].astype('int')\ndf_temp['sec_max'] = df_temp.groupby(['exam_id'])['sec'].transform('max')\ndf_temp['sec_min'] = df_temp.groupby(['exam_id'])['sec'].transform('min')\ndf_temp['sec_range'] = df_temp['sec_max'] - df_temp['sec_min']\ndf_temp = df_temp[['exam_id', 'sec_range']].drop_duplicates()\ndf_feature = df_feature.merge(df_temp, on='exam_id', how='left')\ndel (df_temp)\ngc.collect()\n\n# 考试知识点category数量 (不为0 / 总个数)\ndf_temp = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'category'], {'ratio': ['sum']})\ndf_temp = df_temp[['exam_id', 'category', 'exam_id_category_ratio_sum']]\ndf_temp.drop_duplicates(inplace=True)\ndf_temp = df_temp.groupby(['exam_id'])['exam_id_category_ratio_sum'].\\\n            apply(lambda x: (x != 0).sum() / x.shape[0]).reset_index().rename(columns={'exam_id_category_ratio_sum': 'exam_category_num'})\ndf_feature = df_feature.merge(df_temp, on='exam_id', how='left')\ndel (df_temp)\ngc.collect()\n\n# 考试知识点category max-min\ndf_temp = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'category'], {'ratio': ['sum']})\ndf_temp = df_temp[['exam_id', 'category', 'exam_id_category_ratio_sum']]\ndf_temp.drop_duplicates(inplace=True)\ndf_temp = df_temp[df_temp.exam_id_category_ratio_sum != 0]\ndf_temp['cat'] = df_temp['category'].str.split(':', expand=True)[1]\ndf_temp['cat'] = df_temp['cat'].astype('int')\ndf_temp['cat_max'] = df_temp.groupby(['exam_id'])['cat'].transform('max')\ndf_temp['cat_min'] = df_temp.groupby(['exam_id'])['cat'].transform('min')\ndf_temp['cat_range'] = df_temp['cat_max'] - df_temp['cat_min']\ndf_temp = df_temp[['exam_id', 'cat_range']].drop_duplicates()\ndf_feature = df_feature.merge(df_temp, on='exam_id', how='left')\ndel (df_temp)\ngc.collect()\n\n# 考试的各难度占比\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                                  on=['knowledge_point'],\n                                                  how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'complexity', 'ratio']]\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'complexity'], {'ratio': ['sum']})\np = gen_feature(df_temp, 'exam_id', 'complexity', 'exam_id_complexity_ratio_sum')\ndf_feature = df_feature.merge(p, on='exam_id', how='left')\n\ndel (df_course_exam_feature)\ndel (df_temp)\ndel (p)\ngc.collect()\n\n# 考试总体难度\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_course_exam_feature['complexity_ratio'] = df_course_exam_feature['ratio'] * df_course_exam_feature['complexity'] * 0.01\ndf_exam_complexity_sum = df_course_exam_feature.groupby(['exam_id'])['complexity_ratio'].sum().reset_index()\ndf_exam_complexity_sum.rename(columns={'complexity_ratio': 'exam_complexity'}, inplace=True)\ndf_feature = df_feature.merge(df_exam_complexity_sum, on='exam_id',  how='left')\n\ndel (df_course_exam_feature)\ndel (df_exam_complexity_sum)\ngc.collect()\n\n# course_class 属性\ndf_feature = df_feature.merge(df_course, on='course', how='left')\n\n# 学生课程最近三次考试平均成绩\ndf_score = pd.concat([df_train_score, df_test_score])\ndf_temp = df_score.merge(df_exams_orders, how='left')\ndf_temp['rank'] = df_temp.groupby(['exam_id'])['score'].rank(method='min',\n                                                            ascending=False)\ndf_temp.sort_values(['student_id', 'course', 'order'], inplace=True)\n\ndf_feature = stat_time(df_temp, df_feature, 3, ['student_id', 'course'], 'score', 'mean')\ndf_feature = stat_time(df_temp, df_feature, 3, ['student_id', 'course'], 'score', 'std')\ndf_feature = stat_time(df_temp, df_feature, 3, ['student_id', 'course'], 'rank', 'mean')\ndf_feature = stat_time(df_temp, df_feature, 3, ['student_id', 'course'], 'rank', 'std')\n\ndf_temp = df_temp.merge(df_feature[['student_id', 'course', 'order', 'pre_3_score_mean']], how='left')\ndf_feature = stat_time(df_temp, df_feature, 8, ['student_id', 'course'], 'pre_3_score_mean', 'mean')\n\ndf_temp['pre_3_score_diff_mean'] = df_temp.groupby(\n        ['student_id', 'course'])['score'].shift(1).diff().rolling(window=3, min_periods=1).mean()\ndf_temp = df_temp[['student_id', 'course', 'order', 'pre_3_score_diff_mean']]\ndf_feature = df_feature.merge(df_temp, on=['student_id', 'course', 'order'], how='left')\n\ndf_temp = df_temp.merge(df_feature[['student_id', 'course', 'order', 'pre_3_score_mean']], how='left')\ndf_temp['pre_3_pre_3_score_mean_diff_mean'] = df_temp.groupby(\n        ['student_id', 'course'])['pre_3_score_mean'].shift(1).diff().rolling(window=3, min_periods=1).mean()\ndf_temp = df_temp[['student_id', 'course', 'order', 'pre_3_pre_3_score_mean_diff_mean']]\ndf_feature = df_feature.merge(df_temp, on=['student_id', 'course', 'order'], how='left')\n\ndel (df_score)\ndel (df_temp)\ngc.collect()\n\n# 最近三次考试成绩\ndf_temp = df_feature[['student_id', 'course', 'order', 'score']]\ndf_temp.sort_values(['student_id', 'course', 'order'], inplace=True)\ngg = df_temp.groupby(['student_id', 'course'])\nfor i in range(3):\n    df_temp['pre_{}_score'.format(i+1)] = gg['score'].shift(i+1)\n\ndf_temp.drop(['score'], axis=1, inplace=True)\ndf_feature = df_feature.merge(df_temp, on=['student_id', 'course', 'order'], how='left')\ndel (df_temp)\ngc.collect()\n\n# 嫁接\ndf_jiajie = pd.read_csv(os.path.join(current_path, 'jiajie.csv'))\ndf_feature = df_feature.merge(df_jiajie, on=['student_id', 'exam_id'], how='left')\ndel(df_jiajie)\ngc.collect()","execution_count":14},{"metadata":{"id":"49A085D8BCFB44318F5DD490FAD6C50A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 知识点个数 考试难度 拼接\ndf_temp = df_exams_ratio.groupby(['exam_id'])['ratio'].apply(lambda x: (x != 0).sum()).\\\n        reset_index().rename(columns={'ratio': 'exam_kp_num'})\ndf_temp = df_temp.merge(df_feature[['exam_id', 'exam_complexity']].drop_duplicates(), how='left')\ndf_temp['exam_kp_num_exam_complexity'] = df_temp['exam_kp_num'].astype('str') + df_temp['exam_complexity'].astype('str')\ndf_temp['exam_kp_num_exam_complexity'] = df_temp['exam_kp_num_exam_complexity'].astype('float')\ndf_feature = df_feature.merge(df_temp[['exam_id', 'exam_kp_num_exam_complexity']], how='left')\n\ndel(df_temp)\ngc.collect()","execution_count":17},{"metadata":{"id":"44286DBB37A546FE933FD053A7847E6C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_feature.tail()","execution_count":18},{"metadata":{"id":"09AD05BD81934F5488E0CF313FB4A304","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"seed = 2008","execution_count":19},{"metadata":{"id":"87888954168D4DF383CD61153952B700","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 考试的知识点占比\ndimension1 = 60\n\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'knowledge_point', 'ratio']]\np = gen_feature(df_temp, 'exam_id', 'knowledge_point', 'ratio')\ndf_sparse_f = p.drop(['exam_id'], axis=1)\ndf_exam_f = p[['exam_id']]\npca = PCA(n_components=dimension1, random_state=seed)\ndf_no_sparse_f = pd.DataFrame(pca.fit_transform(df_sparse_f))\ndf_no_sparse_f.columns = [ 'exam_point_ratio' + str(c) for c in df_no_sparse_f.columns]\ndf_exam_f = pd.concat([df_exam_f, df_no_sparse_f], axis=1)\ndf_feature = df_feature.merge(df_exam_f, on='exam_id', how='left')\n\ndel (df_course_exam_feature)\ndel (df_temp)\ndel (df_sparse_f)\ndel (df_exam_f)\ndel (df_no_sparse_f)\ndel (p)\ngc.collect()\n\ndf_feature.shape","execution_count":20},{"metadata":{"id":"4A942384E3D64C0F8576A3C1F1B3D694","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 考试各段落和种类占比\ndimension2 = 60\n\ndf_course_exam_feature = df_exams_ratio.merge(df_knowledge,\n                                              on=['knowledge_point'],\n                                              how='left')\ndf_temp = df_course_exam_feature[['exam_id', 'section', 'category', 'ratio']]\n\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'section'], {'ratio': ['sum']})\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'category'], {'ratio': ['sum']})\n\ndf_exam_f = df_temp[['exam_id']]\ndf_exam_f.drop_duplicates(inplace=True)\np = gen_feature(df_temp, 'exam_id', 'section', 'exam_id_section_ratio_sum')\ndf_exam_f = df_exam_f.merge(p, on='exam_id', how='left')\np = gen_feature(df_temp, 'exam_id', 'category', 'exam_id_category_ratio_sum')\ndf_exam_f = df_exam_f.merge(p, on='exam_id', how='left')\n\ndf_sparse_f = df_exam_f.drop(['exam_id'], axis=1)\ndf_exam_f = df_exam_f[['exam_id']]\npca = PCA(n_components=dimension2, random_state=seed)\ndf_no_sparse_f = pd.DataFrame(pca.fit_transform(df_sparse_f))\ndf_no_sparse_f.columns = [\n    'exam_section_cat_ratio' + str(c) for c in df_no_sparse_f.columns\n]\ndf_exam_f = pd.concat([df_exam_f, df_no_sparse_f], axis=1)\ndf_feature = df_feature.merge(df_exam_f, on='exam_id', how='left')\n\ndel (df_course_exam_feature)\ndel (df_temp)\ndel (df_sparse_f)\ndel (df_exam_f)\ndel (df_no_sparse_f)\ndel (p)\ngc.collect()\n\ndf_feature.shape","execution_count":21},{"metadata":{"id":"3CFE7D6B1A3643DA87E73ADF8ED5A09D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 根据知识点分布找相似特征\nK = 3\ndf_temp = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_temp = df_temp[['exam_id', 'knowledge_point', 'ratio']]\np = gen_feature(df_temp, 'exam_id', 'knowledge_point', 'ratio')\n\nindex = list(p.index.values)\nexam_ids = list(p['exam_id'].values)\nindex_exam_map = dict(zip(index,exam_ids))\n\np.drop(['exam_id'], axis=1, inplace=True)\nnbrs = NearestNeighbors(n_neighbors=K+1, algorithm=\"auto\").fit(p)\ndistances, indices = nbrs.kneighbors(p)\ndf_distance = pd.DataFrame(distances)\ndf_distance.drop([0], axis=1, inplace=True)\ndf_distance.columns = ['dis_'+str(c) for c in df_distance.columns]\ndf_distance = df_distance.apply(lambda x: 1/(x+10**-6), axis=1)\n\ndf_indice = pd.DataFrame(indices)\ndf_indice.drop([0], axis=1, inplace=True)\ndf_indice = df_indice.replace(index_exam_map)\ndf_indice.columns = ['sim_exam_'+str(c) for c in df_indice.columns]\n\ndf_sim_exam = pd.concat([df_distance, df_indice], axis=1)\ndf_sim_exam['exam_id'] = exam_ids\n\ndf_sim_exam = df_sim_exam.merge(df_feature[['student_id' ,'exam_id']], on='exam_id', how='right')\nfor i in range(K):\n    df_sim_exam = df_sim_exam.merge(df_train_score[['student_id', 'exam_id', 'score']].rename(columns={'exam_id': 'eid'}),\n                                    left_on=['student_id', 'sim_exam_'+str(i+1)],\n                                    right_on=['student_id', 'eid'], how='left')\n    df_sim_exam['sim_score_'+str(i+1)] = df_sim_exam['score']\n    df_sim_exam.drop(['score', 'eid'], axis=1, inplace=True)\n\ndef cal_score(x):\n    sum_dis = 0\n    sim_score = 0\n    for i in range(K):\n        if x['sim_score_'+str(i+1)] == 0:\n            x['dis_'+str(i+1)] = 0\n            x['sim_score_'+str(i+1)] = 0\n        sum_dis += x['dis_'+str(i+1)]\n    for i in range(K):\n        sim_score += x['dis_'+str(i+1)] / sum_dis * x['sim_score_'+str(i+1)]\n\n    return sim_score\n\ndf_sim_exam.fillna(0, inplace=True)\ndf_sim_exam['sim_exam_score'] = df_sim_exam.apply(cal_score, axis=1)\n\ndf_feature = df_feature.merge(df_sim_exam[['student_id' ,'exam_id', 'sim_exam_score']], on=['student_id', 'exam_id'], how='left')\ndel(df_temp)\ndel(p)\ndel(df_distance)\ndel(df_indice)\ndel(df_sim_exam)\n\ngc.collect()","execution_count":22},{"metadata":{"id":"218044CA29C14AFE8A36B540BD84D3B4","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 根据 section 分布找相似试卷\nK = 3\ndf_temp = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_temp = df_temp[['exam_id', 'section', 'ratio']]\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'section'], {'ratio': ['sum']})\np = gen_feature(df_temp, 'exam_id', 'section', 'exam_id_section_ratio_sum')\n\nindex = list(p.index.values)\nexam_ids = list(p['exam_id'].values)\nindex_exam_map = dict(zip(index,exam_ids))\n\np.drop(['exam_id'], axis=1, inplace=True)\nnbrs = NearestNeighbors(n_neighbors=K+1, algorithm=\"auto\").fit(p)\ndistances, indices = nbrs.kneighbors(p)\ndf_distance = pd.DataFrame(distances)\ndf_distance.drop([0], axis=1, inplace=True)\ndf_distance.columns = ['dis_'+str(c) for c in df_distance.columns]\ndf_distance = df_distance.apply(lambda x: 1/(x+10**-6), axis=1)\n\ndf_indice = pd.DataFrame(indices)\ndf_indice.drop([0], axis=1, inplace=True)\ndf_indice = df_indice.replace(index_exam_map)\ndf_indice.columns = ['sim_exam_'+str(c) for c in df_indice.columns]\n\ndf_sim_exam = pd.concat([df_distance, df_indice], axis=1)\ndf_sim_exam['exam_id'] = exam_ids\n\ndf_sim_exam = df_sim_exam.merge(df_feature[['student_id' ,'exam_id']], on='exam_id', how='right')\nfor i in range(K):\n    df_sim_exam = df_sim_exam.merge(df_train_score[['student_id', 'exam_id', 'score']].rename(columns={'exam_id': 'eid'}),\n                                    left_on=['student_id', 'sim_exam_'+str(i+1)],\n                                    right_on=['student_id', 'eid'], how='left')\n    df_sim_exam['sim_score_'+str(i+1)] = df_sim_exam['score']\n    df_sim_exam.drop(['score', 'eid'], axis=1, inplace=True)\n\ndef cal_score(x):\n    sum_dis = 0\n    sim_score = 0\n    for i in range(K):\n        if x['sim_score_'+str(i+1)] == 0:\n            x['dis_'+str(i+1)] = 0\n            x['sim_score_'+str(i+1)] = 0\n        sum_dis += x['dis_'+str(i+1)]\n    if sum_dis == 0:\n        return np.nan\n    for i in range(K):\n        sim_score += x['dis_'+str(i+1)] / sum_dis * x['sim_score_'+str(i+1)]\n\n    return sim_score\n\ndf_sim_exam.fillna(0, inplace=True)\ndf_sim_exam['sim_exam_form_section_score'] = df_sim_exam.apply(cal_score, axis=1)\n\ndf_feature = df_feature.merge(df_sim_exam[['student_id' ,'exam_id', 'sim_exam_form_section_score']], \n                              on=['student_id', 'exam_id'], how='left')\ndel(df_temp)\ndel(p)\ndel(df_distance)\ndel(df_indice)\ndel(df_sim_exam)\n\ngc.collect()","execution_count":23},{"metadata":{"id":"61C17C9C922C47C38CFAB19376AADCEA","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 根据 category 分布找相似试卷\nK = 3\ndf_temp = df_exams_ratio.merge(df_knowledge, on=['knowledge_point'], how='left')\ndf_temp = df_temp[['exam_id', 'category', 'ratio']]\ndf_temp = stat(df_temp, df_temp, ['exam_id', 'category'], {'ratio': ['sum']})\np = gen_feature(df_temp, 'exam_id', 'category', 'exam_id_category_ratio_sum')\nindex = list(p.index.values)\nexam_ids = list(p['exam_id'].values)\nindex_exam_map = dict(zip(index,exam_ids))\n\nfrom sklearn.neighbors import NearestNeighbors\np.drop(['exam_id'], axis=1, inplace=True)\nnbrs = NearestNeighbors(n_neighbors=K+1, algorithm=\"auto\").fit(p)\ndistances, indices = nbrs.kneighbors(p)\ndf_distance = pd.DataFrame(distances)\ndf_distance.drop([0], axis=1, inplace=True)\ndf_distance.columns = ['dis_'+str(c) for c in df_distance.columns]\ndf_distance = df_distance.apply(lambda x: 1/(x+10**-6), axis=1)\n\ndf_indice = pd.DataFrame(indices)\ndf_indice.drop([0], axis=1, inplace=True)\ndf_indice = df_indice.replace(index_exam_map)\ndf_indice.columns = ['sim_exam_'+str(c) for c in df_indice.columns]\n\ndf_sim_exam = pd.concat([df_distance, df_indice], axis=1)\ndf_sim_exam['exam_id'] = exam_ids\n\ndf_sim_exam = df_sim_exam.merge(df_feature[['student_id' ,'exam_id']], on='exam_id', how='right')\nfor i in range(K):\n    df_sim_exam = df_sim_exam.merge(df_train_score[['student_id', 'exam_id', 'score']].rename(columns={'exam_id': 'eid'}),\n                                    left_on=['student_id', 'sim_exam_'+str(i+1)],\n                                    right_on=['student_id', 'eid'], how='left')\n    df_sim_exam['sim_score_'+str(i+1)] = df_sim_exam['score']\n    df_sim_exam.drop(['score', 'eid'], axis=1, inplace=True)\n\ndef cal_score(x):\n    sum_dis = 0\n    sim_score = 0\n    for i in range(K):\n        if x['sim_score_'+str(i+1)] == 0:\n            x['dis_'+str(i+1)] = 0\n            x['sim_score_'+str(i+1)] = 0\n        sum_dis += x['dis_'+str(i+1)]\n    if sum_dis == 0:\n        return np.nan\n    for i in range(K):\n        sim_score += x['dis_'+str(i+1)] / sum_dis * x['sim_score_'+str(i+1)]\n\n    return sim_score\n\ndf_sim_exam.fillna(0, inplace=True)\ndf_sim_exam['sim_exam_form_category_score'] = df_sim_exam.apply(cal_score, axis=1)\n\ndf_feature = df_feature.merge(df_sim_exam[['student_id' ,'exam_id', 'sim_exam_form_category_score']], \n                              on=['student_id', 'exam_id'], how='left')\ndel(df_temp)\ndel(p)\ndel(df_distance)\ndel(df_indice)\ndel(df_sim_exam)\n\ngc.collect()","execution_count":24},{"metadata":{"id":"300CE4813E684A859676E58F8848436A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_feature.head()","execution_count":25},{"metadata":{"id":"6B4D5F5BD59C4AE68C42FBFEE9452926","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 关于 score 的统计特征\ndef statis_feat(df_know, df_unknow):\n    # 成绩 max mean std cv\n    df_unknow = stat(df_know, df_unknow, ['student_id'], {'score': ['max', 'mean', 'std', 'median']})\n    df_unknow = stat_cv(df_know, df_unknow, ['student_id'], 'score')\n    \n    # mean(个人考试成绩 / 本次考试平均成绩)\n    df_unknow = stat_ratio_mean(df_know, df_unknow, ['student_id'])\n    \n    # 平均排名\n    df_unknow = stat_rank(df_know, df_unknow, ['student_id'])\n    \n    # score / 难度 衡量学生抗压能力\n    df_know['s/c'] = df_know['score'] / df_know['exam_complexity']\n\n    df_unknow = stat(df_know, df_unknow, ['student_id'], {'s/c': ['mean', 'std', 'max', 'median']})\n    df_unknow = stat(df_know, df_unknow, ['student_id', 'course'], {'s/c': ['mean', 'std', 'max', 'median']})\n    df_unknow = stat_cv(df_know, df_unknow, ['student_id', 'course'], 's/c')\n    df_unknow = stat_cv(df_know, df_unknow, ['student_id'], 's/c')\n    \n    df_know.drop(['s/c'], axis=1, inplace=True)\n    \n    # ******* 课程特征 ******** #\n    # max mean std cv\n    df_unknow = stat(df_know, df_unknow, ['course'], {'score': ['mean', 'std']})\n    df_unknow = stat_cv(df_know, df_unknow, ['course'], 'score')\n    \n    # ******* 学生，课程组合特征 ******** #\n    # max mean std cv\n    df_unknow = stat(df_know, df_unknow, ['student_id', 'course'], {'score': ['max', 'mean', 'std', 'median']})\n    df_unknow = stat_cv(df_know, df_unknow, ['student_id', 'course'], 'score')\n    df_unknow = stat(df_know, df_unknow, ['student_id', 'course_class'], {'score': ['max', 'mean', 'std', 'median']})\n    df_unknow = stat_cv(df_know, df_unknow, ['student_id', 'course_class'], 'score')\n    \n    # 课程平均排名\n    df_unknow = stat_rank(df_know, df_unknow, ['student_id', 'course'])\n    \n    # 课程平均分\n    df_unknow = stat_ratio_mean(df_know, df_unknow, ['student_id', 'course'])\n    \n    # 性别在课程考试 max mean std cv\n    df_unknow = stat(df_know, df_unknow, ['gender', 'course'], {'score': ['mean', 'std', 'median']})\n    df_unknow = stat_cv(df_know, df_unknow, ['gender', 'course'], 'score')\n    \n    return df_unknow","execution_count":26},{"metadata":{"id":"09CCF5B62F044B4F8C6221AAFFECC27A","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 5折交叉 有关 score 的特征构造\ndf_train = df_feature[~df_feature['score'].isnull()]\ndf_train = df_train.reset_index(drop=True)\ndf_test = df_feature[df_feature['score'].isnull()]\n        \nseed = 2008\ndf_stas_feat = None\nkf = KFold(n_splits=5, random_state=2018, shuffle=True)\nfor train_index, val_index in kf.split(df_train):\n    df_fold_train = df_train.iloc[train_index]\n    df_fold_val = df_train.iloc[val_index]\n    \n    df_fold_val = statis_feat(df_fold_train, df_fold_val)\n    df_stas_feat = pd.concat([df_stas_feat, df_fold_val], axis=0)\n    \n    del(df_fold_train)\n    del(df_fold_val)\n    gc.collect()\n\ndf_test = statis_feat(df_train, df_test)\ndf_feature = pd.concat([df_stas_feat, df_test], axis=0)\n\ndel(df_stas_feat)\ndel(df_train)\ndel(df_test)\ngc.collect()","execution_count":27},{"metadata":{"id":"87272C4EC23A4B2691AB291B524BD8D0","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# LabelEncoder\nfor f in df_feature.select_dtypes('object'):\n    lbl = LabelEncoder()\n    df_feature[f] = lbl.fit_transform(df_feature[f].astype(str))","execution_count":28},{"metadata":{"id":"F6E0B9C31D1B4F1B890FB4816E8A8899","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_feature = select_feature(df_feature)","execution_count":29},{"metadata":{"id":"7E5ED51AEECD4B3C8F08401136F13EFB","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_train = df_feature.iloc[:df_train_score.shape[0]]\ndf_test = df_feature.iloc[df_train_score.shape[0]:]","execution_count":30},{"metadata":{"id":"587D20F1A3674DCC84C44C2E6180F10D","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"df_train['score'] = np.log1p(df_train['score'])","execution_count":31},{"metadata":{"id":"FD231E45C43E48AB914CCB21A912F122","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def myscore(preds, xgbtrain):\n    label = xgbtrain.get_label()\n    \n    preds = np.expm1(preds)\n    label = np.expm1(label)\n    \n    score = 10 * np.log10(np.sqrt(mean_squared_error(label, preds)))\n    return 'myrmse', score\n\nseed = 2008\nnfold = 5\n\nycol = 'score'\n\nfeature_names = list(\n    filter(lambda x: x not in [ycol, 'student_id', 'kp_distance'], df_train.columns))\n\ntest_pred = pd.read_csv(os.path.join(data_path, 'submission_s2.csv'))\ntest_pred.fillna(0, inplace=True)\n\nkfolder = KFold(n_splits=nfold, shuffle=True, random_state=seed)\nscore_train_total = 0\nscore_val_total = 0\ndf_importance_list = []\nfor fold_id, (trn_idx, val_idx) in enumerate(kfolder.split(df_train)):\n    print(\n        '\\nxgboost Fold_{} Training ================================\\n'.format(\n            fold_id))\n    X_train = df_train.iloc[trn_idx][feature_names]\n    Y_train = df_train.iloc[trn_idx][ycol]\n\n    X_val = df_train.iloc[val_idx][feature_names]\n    Y_val = df_train.iloc[val_idx][ycol]\n\n    model_xgb = xgb.XGBRegressor(random_state=seed,\n                                 max_depth=8,\n                                 n_estimators=20000,\n                                 min_child_weight=300,\n                                 colsample_bytree=0.8,\n                                 subsample=0.8,\n                                 learning_rate=0.01,\n                                 reg_alpha=1,\n                                 reg_lambda=0.8,\n                                 objective=\"reg:linear\")\n    model_xgb.fit(X_train,\n                  Y_train,\n                  eval_set=[(X_train, Y_train), (X_val, Y_val)],\n                  verbose=1000,\n                  early_stopping_rounds=500, \n                  eval_metric=myscore)\n\n    pred_val = model_xgb.predict(X_val)\n    pred_train = model_xgb.predict(X_train)\n    pred_test = model_xgb.predict(df_test[feature_names])\n    \n    # 反变换\n    pred_val = np.expm1(pred_val)\n    pred_train = np.expm1(pred_train)\n    pred_test = np.expm1(pred_test)\n    Y_val = np.expm1(Y_val)\n    Y_train = np.expm1(Y_train)\n\n    score_val = 10 * np.log10(np.sqrt(mean_squared_error(Y_val, pred_val)))\n    score_train = 10 * np.log10(np.sqrt(mean_squared_error(Y_train, pred_train)))\n    \n    score_train_total += score_train\n    score_val_total += score_val\n    print('xgb', score_train, score_val)\n    \n    test_pred['pred'] += pred_test / nfold\n\n    df_importance = pd.DataFrame({\n        'column': feature_names,\n        'importance': model_xgb.feature_importances_,\n    })\n    df_importance_list.append(df_importance)\n\ntest_pred['pred'] = test_pred['pred'].map(lambda x: round(x, 1))\n\ndf_importance = pd.concat(df_importance_list)\ndf_importance = df_importance.groupby(['column'])['importance'].agg('mean').sort_values(ascending=False)\n\ndf_importance.to_csv(os.path.join(current_path, 'importance.csv'))\n\nprint(df_importance.head(10))\nprint(df_importance.tail())\nprint(score_train_total / nfold, score_val_total / nfold)\n\ntest_pred.to_csv(os.path.join(current_path, 'xgb.csv'), index=False)","execution_count":1},{"metadata":{"id":"CFE9AC861AC6466ABBE906A35D4E21B1","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"def myscore(preds, xgbtrain):    \n    preds = np.expm1(preds)\n    xgbtrain = np.expm1(xgbtrain)\n    \n    score = 10 * np.log10(np.sqrt(mean_squared_error(xgbtrain, preds)))\n    return 'myrmse', score, False\n\nseed = 2008\nnfold = 5\n\nycol = 'score'\n\nfeature_names = list(\n    filter(lambda x: x not in [ycol, 'student_id'], df_train.columns))\n\ntest_pred = pd.read_csv(os.path.join(data_path, 'submission_s2.csv'))\ntest_pred.fillna(0, inplace=True)\n\nkfolder = KFold(n_splits=nfold, shuffle=True, random_state=seed)\nscore_train_total = 0\nscore_val_total = 0\ndf_importance_list = []\nfor fold_id, (trn_idx, val_idx) in enumerate(kfolder.split(df_train)):\n    print(\n        '\\nlightgbm Fold_{} Training ================================\\n'.format(\n            fold_id))\n    X_train = df_train.iloc[trn_idx][feature_names]\n    Y_train = df_train.iloc[trn_idx][ycol]\n\n    X_val = df_train.iloc[val_idx][feature_names]\n    Y_val = df_train.iloc[val_idx][ycol]\n\n    model_lgb = lgb.LGBMRegressor(random_state=seed,\n                                  max_depth=8,\n                                  n_estimators=10000,\n                                  min_child_weight=300,\n                                  colsample_bytree=0.8,\n                                  subsample=0.8,\n                                  learning_rate=0.1,\n                                  reg_alpha=1,\n                                  reg_lambda=0.8)\n\n    model_lgb.fit(X_train,\n                  Y_train,\n                  eval_set=[(X_train, Y_train), (X_val, Y_val)],\n                  verbose=1000,\n                  early_stopping_rounds=500, \n                  eval_metric=myscore)\n\n    pred_val = model_lgb.predict(X_val)\n    pred_train = model_lgb.predict(X_train)\n    pred_test = model_lgb.predict(df_test[feature_names])\n    \n    # 反变换\n    pred_val = np.expm1(pred_val)\n    pred_train = np.expm1(pred_train)\n    pred_test = np.expm1(pred_test)\n    Y_val = np.expm1(Y_val)\n    Y_train = np.expm1(Y_train)\n\n    score_val = 10 * np.log10(np.sqrt(mean_squared_error(Y_val, pred_val)))\n    score_train = 10 * np.log10(np.sqrt(mean_squared_error(Y_train, pred_train)))\n    \n    score_train_total += score_train\n    score_val_total += score_val\n    print('lgb', score_train, score_val)\n    \n    test_pred['pred'] += pred_test / nfold\n\n    df_importance = pd.DataFrame({\n        'column': feature_names,\n        'importance': model_lgb.feature_importances_,\n    })\n    df_importance_list.append(df_importance)\n\ntest_pred['pred'] = test_pred['pred'].map(lambda x: round(x, 1))\n\ndf_importance = pd.concat(df_importance_list)\ndf_importance = df_importance.groupby(['column'])['importance'].agg('mean').sort_values(ascending=False)\n\ndf_importance.to_csv(os.path.join(current_path, 'importance.csv'))\n\nprint(df_importance.head(10))\nprint(df_importance.tail())\nprint(score_train_total / nfold, score_val_total / nfold)\n\ntest_pred.to_csv(os.path.join(current_path, 'lgb.csv'), index=False)","execution_count":33},{"metadata":{"id":"8730A2DAD26E47FB80610AE53B18B61C","collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 融合\ndf_xgb = pd.read_csv(os.path.join(current_path, 'xgb.csv'))\ndf_xgb.rename(columns={'pred': 'xgb'}, inplace=True)\ndf_lgb = pd.read_csv(os.path.join(current_path, 'lgb.csv'))\ndf_lgb.rename(columns={'pred': 'lgb'}, inplace=True)\n\ndf_all = df_xgb.merge(df_lgb, how='left')\ndf_all['pred'] = (df_all['xgb'] + df_all['lgb']) / 2\ndf_all = df_all[['student_id', 'course', 'exam_id', 'pred']]\ndf_all.to_csv(os.path.join(current_path, 'submit.csv'), index=False)","execution_count":31}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":0}